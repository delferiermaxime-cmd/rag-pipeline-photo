# RAG Local ğŸ”

Application RAG (**Retrieval-Augmented Generation**) auto-hÃ©bergÃ©e permettant d'interroger vos documents via un LLM local. Aucune donnÃ©e ne quitte votre serveur.

---

## Table des matiÃ¨res

- [Architecture](#architecture)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Configuration](#configuration)
- [Mise Ã  jour](#mise-Ã -jour)
- [Utilisation](#utilisation)
- [ParamÃ¨tres](#paramÃ¨tres)
- [RÃ©solution d'erreurs](#rÃ©solution-derreurs)

---

## Architecture

```
Browser â†’ Nginx (port 80)
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Frontend        â”‚  Next.js (port 3000)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ /api/*
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Backend        â”‚  FastAPI (port 8000)
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚      â”‚       â”‚
  â”Œâ”€â”€â”€â”€â–¼â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”
  â”‚Ollamaâ”‚ â”‚Qdrantâ”‚  â”‚Postgresâ”‚
  â”‚LLM + â”‚ â”‚Vect. â”‚  â”‚Users + â”‚
  â”‚Embed.â”‚ â”‚Base  â”‚  â”‚Docs +  â”‚
  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜  â”‚Histor. â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pipeline RAG :**
```
Fichier â†’ Docling â†’ Markdown â†’ Chunks (3000 chars, overlap 450) â†’ bge-m3 â†’ Qdrant
Question â†’ bge-m3 â†’ Qdrant (similaritÃ© cosine) â†’ TOP_K chunks â†’ LLM â†’ RÃ©ponse SSE
```

**Stack technique :**
| Composant | Technologie |
|---|---|
| Frontend | Next.js 14, TypeScript |
| Backend | FastAPI, SQLAlchemy async |
| Base vectorielle | Qdrant |
| Base de donnÃ©es | PostgreSQL 16 |
| LLM & Embedding | Ollama (gemma3, llama3.1, bge-m3...) |
| Parser de documents | Docling |
| Reverse proxy | Nginx |

---

## PrÃ©requis

- **OS** : Linux (Ubuntu 22.04+ recommandÃ©)
- **RAM** : 8 GB minimum, 16 GB recommandÃ© (selon le modÃ¨le LLM)
- **Stockage** : 20 GB minimum (modÃ¨les LLM inclus)
- **Docker** : 24.0+
- **Docker Compose** : 2.20+
- **Git**

VÃ©rifier les versions :
```bash
docker --version
docker compose version
git --version
```

---

## Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/delferiermaxime-cmd/rag-pipeline-photo.git
cd rag-pipeline
```

### 2. Configurer les variables d'environnement

```bash
cp .env.example .env
nano .env
```

Contenu minimal du `.env` :
```env
SECRET_KEY=changez-moi-avec-une-cle-tres-longue-et-aleatoire
CORS_ORIGINS=http://localhost,http://votre-ip-serveur
```

GÃ©nÃ©rer une clÃ© secrÃ¨te sÃ©curisÃ©e :
```bash
python3 -c "import secrets; print(secrets.token_hex(32))"
```

### 3. Build et dÃ©marrage

```bash
docker compose build --no-cache
docker compose up -d
```

> â± Le premier build prend **10-15 minutes** (tÃ©lÃ©chargement de Docling et ses modÃ¨les).

### 4. TÃ©lÃ©charger les modÃ¨les Ollama

```bash
# ModÃ¨le LLM (obligatoire)
docker compose exec ollama ollama pull gemma3:4b

# ModÃ¨le d'embedding (obligatoire)
docker compose exec ollama ollama pull bge-m3:567m
```

> â± `gemma3:4b` = ~3 GB, `bge-m3:567m` = ~600 MB

### 5. VÃ©rifier que tout fonctionne

```bash
docker compose ps
```

Tous les containers doivent Ãªtre en Ã©tat `Up` :
```
rag-pipeline-backend-1    Up
rag-pipeline-frontend-1   Up
rag-pipeline-nginx-1      Up
rag-pipeline-ollama-1     Up
rag-pipeline-postgres-1   Up
rag-pipeline-qdrant-1     Up
```

### 6. AccÃ©der Ã  l'application

Ouvrir **http://votre-ip-serveur** dans le navigateur, crÃ©er un compte et commencer Ã  uploader des documents.

---

## Configuration

### Variables d'environnement (`.env`)

| Variable | Description | DÃ©faut |
|---|---|---|
| `SECRET_KEY` | ClÃ© JWT â€” **obligatoire, changer en production** | â€” |
| `CORS_ORIGINS` | Origines autorisÃ©es (sÃ©parÃ©es par virgule) | `http://localhost` |

### ModÃ¨les LLM disponibles (`docker-compose.yml`)

Par dÃ©faut :
```yaml
OLLAMA_AVAILABLE_MODELS: gemma3:4b,llama3.1:latest,deepseek-r1:14b,gemma3:12b,gemma3:27b
```

Pour ajouter un modÃ¨le :
```bash
# 1. TÃ©lÃ©charger le modÃ¨le
docker compose exec ollama ollama pull llama3.2:latest

# 2. L'ajouter dans docker-compose.yml
OLLAMA_AVAILABLE_MODELS: gemma3:4b,llama3.1:latest,llama3.2:latest

# 3. RedÃ©marrer le backend
docker compose restart backend
```

Parcourir tous les modÃ¨les disponibles : **https://ollama.com/library**

### Formats de documents supportÃ©s

| Format | Extension | Parser |
|---|---|---|
| PDF | `.pdf` | Docling + PyPdfium |
| Word | `.docx`, `.dotx`, `.doc` | Docling |
| PowerPoint | `.pptx`, `.ppt` | Docling |
| Excel | `.xlsx`, `.xls` | Docling |
| HTML | `.html`, `.htm` | Docling |
| Texte | `.txt`, `.md`, `.csv` | Fallback natif |
| EPUB | `.epub` | Docling |
| AsciiDoc | `.asciidoc`, `.adoc` | Docling |

---

## Mise Ã  jour

### Mise Ã  jour du code

```bash
cd ~/rag-pipeline

# 1. RÃ©cupÃ©rer les derniÃ¨res modifications
git pull

# 2. Rebuild complet
docker compose build --no-cache

# 3. RedÃ©marrer
docker compose up -d
```

> âš ï¸ Le rebuild recompile les images Docker mais **ne supprime pas les donnÃ©es** (PostgreSQL, Qdrant, modÃ¨les Ollama sont dans des volumes persistants).

### Mise Ã  jour rapide (backend uniquement, sans rebuild)

Pour appliquer un changement backend rapidement :
```bash
git pull

docker compose cp backend/app/services/rag_service.py rag-pipeline-backend-1:/app/app/services/rag_service.py
docker compose cp backend/app/routers/chat.py rag-pipeline-backend-1:/app/app/routers/chat.py
# ... autres fichiers modifiÃ©s

docker compose restart backend
```

> âš ï¸ Les changements frontend nÃ©cessitent toujours un rebuild complet (`docker compose build --no-cache frontend`).

### VÃ©rifier les donnÃ©es aprÃ¨s mise Ã  jour

```bash
# Compter les documents en base
docker compose exec postgres psql -U raguser -d ragdb -c "SELECT COUNT(*) FROM documents;"

# Compter les vecteurs Qdrant
curl http://localhost/api/v1/documents/ -H "Authorization: Bearer TOKEN"
```

---

## Utilisation

### Uploader des documents (base vectorielle partagÃ©e)

1. Aller dans **Upload**
2. Glisser-dÃ©poser ou cliquer pour parcourir
3. Attendre le statut **âœ… X chunks indexÃ©s**
4. Les documents sont accessibles par **tous les utilisateurs**

### Interroger les documents

1. Aller dans **Chat**
2. Taper une question â†’ le LLM rÃ©pond en streaming
3. Les **sources** sont affichÃ©es avec le score de similaritÃ© et la page
4. Si la rÃ©ponse n'est pas dans les documents, le LLM rÃ©pond depuis ses connaissances gÃ©nÃ©rales

### Upload temporaire dans la conversation

Cliquer sur ğŸ“ dans le chat pour joindre un fichier **sans l'indexer** dans la base vectorielle. Le contenu est injectÃ© directement dans le contexte de la conversation.

### Historique

Cliquer sur **Historique** dans le chat pour retrouver les conversations prÃ©cÃ©dentes. Chaque conversation est sauvegardÃ©e automatiquement.

---

## ParamÃ¨tres

Accessible via **ParamÃ¨tres** dans la sidebar.

| ParamÃ¨tre | Description | DÃ©faut |
|---|---|---|
| **Prompt systÃ¨me** | Instructions donnÃ©es au LLM avant chaque rÃ©ponse | Voir app |
| **TempÃ©rature** | 0 = dÃ©terministe Â· 1 = crÃ©atif | 0.1 |
| **Tokens max** | Longueur maximale de la rÃ©ponse | 1024 |
| **TOP_K** | Nombre de chunks rÃ©cupÃ©rÃ©s depuis Qdrant | 5 |
| **Score minimum** | Seuil de similaritÃ© â€” chunks en dessous ignorÃ©s | 0.3 |
| **Contexte max** | Taille max du contexte envoyÃ© au LLM | 12 000 chars |

Les paramÃ¨tres sont sauvegardÃ©s localement dans le navigateur (localStorage).

---

## RÃ©solution d'erreurs

### Commandes de diagnostic gÃ©nÃ©rales

```bash
# Ã‰tat de tous les containers
docker compose ps

# Logs backend (erreurs les plus frÃ©quentes)
docker compose logs backend --tail=50

# Logs frontend
docker compose logs frontend --tail=30

# Tester la connectivitÃ© backend
curl http://localhost/api/v1/health 2>/dev/null || echo "Backend inaccessible"
```

---

### âŒ `Docling non installÃ©`

**Cause :** La classe d'import a changÃ© selon la version de Docling.

```bash
# VÃ©rifier les classes disponibles
docker compose exec backend python -c "
import docling.backend.pypdfium2_backend as b
print([x for x in dir(b) if 'Backend' in x])
"

# VÃ©rifier si Docling est bien chargÃ©
docker compose exec backend python -c "
from app.services.docling_service import _DOCLING_OK
print('Docling OK:', _DOCLING_OK)
"
```

**Fix :** Si `_DOCLING_OK` est `False`, vÃ©rifier le log d'erreur et corriger l'import dans `docling_service.py`. Le bon nom de classe est `PyPdfiumDocumentBackend` (sans le `2`).

---

### âŒ `File format not allowed`

**Cause :** Docling ne supporte pas le format `.txt` en natif â€” il doit Ãªtre traitÃ© via le fallback.

**Fix :** S'assurer que `.txt` et `.md` ne sont **pas** dans `EXT_TO_FORMAT` du bloc `if _DOCLING_OK`.

---

### âŒ Le LLM ne rÃ©pond pas / `Load failed`

```bash
# 1. VÃ©rifier qu'Ollama tourne
docker compose exec ollama ollama list

# 2. Tester Ollama directement
curl http://localhost:11434/api/tags 2>/dev/null | python3 -m json.tool

# 3. Tester le chat via l'API
TOKEN=$(curl -s -X POST http://localhost/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"TON_USER","password":"TON_MOT_DE_PASSE"}' \
  | python3 -c "import sys,json; print(json.load(sys.stdin)['access_token'])")

curl -X POST http://localhost/api/v1/chat/stream \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"question":"bonjour","model":"gemma3:4b"}' \
  --no-buffer -s | head -10
```

Si le curl retourne des tokens `data: {"type": "token"...}` â†’ le problÃ¨me est dans le frontend (rebuild nÃ©cessaire).

Si erreur `ModÃ¨le non disponible` â†’ le modÃ¨le n'est pas tÃ©lÃ©chargÃ© :
```bash
docker compose exec ollama ollama pull gemma3:4b
```

---

### âŒ `SSE` / rÃ©ponse vide sans erreur

**Cause :** Nginx buffÃ©rise le stream SSE.

**Fix :** VÃ©rifier `nginx.conf` â€” la route `/api/v1/chat/stream` doit avoir :
```nginx
proxy_buffering off;
proxy_cache off;
proxy_read_timeout 300s;
```

---

### âŒ Inscription / connexion Ã©choue

```bash
# Tester l'inscription
curl -X POST http://localhost/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test@test.com","username":"testuser","password":"motdepasse123"}' -v
```

**Erreur bcrypt** (`password cannot be longer than 72 bytes`) :
```bash
# VÃ©rifier la version de bcrypt
docker compose exec backend pip show bcrypt | grep Version
# Doit Ãªtre 4.0.1
```

Si version incorrecte â†’ vÃ©rifier `backend/requirements.txt` : `bcrypt==4.0.1`

---

### âŒ Page Documents affiche 0 document

**Cause :** Les documents ont Ã©tÃ© uploadÃ©s avec un autre compte utilisateur.

```bash
# VÃ©rifier qui a uploadÃ© quoi
docker compose exec postgres psql -U raguser -d ragdb -c "
SELECT d.original_name, d.status, u.username
FROM documents d
JOIN users u ON d.user_id = u.id;"
```

**Fix :** S'assurer que le filtre `user_id` est retirÃ© dans `documents.py` (base partagÃ©e) ou se connecter avec le bon compte.

---

### âŒ Container crash au dÃ©marrage

```bash
# Voir les logs du container qui crash
docker compose logs backend --tail=100
docker compose logs frontend --tail=50

# Rebuild propre
docker compose down
docker compose build --no-cache
docker compose up -d
```

---

### âŒ Erreur de base de donnÃ©es

```bash
# VÃ©rifier que PostgreSQL tourne
docker compose exec postgres psql -U raguser -d ragdb -c "SELECT version();"

# Lister les tables
docker compose exec postgres psql -U raguser -d ragdb -c "\dt"

# Tables attendues : users, documents, conversations, chat_messages
```

Si les tables manquent, le backend les recrÃ©e automatiquement au dÃ©marrage (`init_db()`).

---

### âŒ Qdrant inaccessible

```bash
# Tester Qdrant directement
curl http://localhost:6333/collections

# Lister les collections
curl http://localhost:6333/collections/documents/info
```

---

### ğŸ”„ RÃ©initialisation complÃ¨te (donnÃ©es effacÃ©es)

> âš ï¸ **Destructif** â€” supprime tous les utilisateurs, documents et vecteurs.

```bash
docker compose down -v   # -v supprime les volumes
docker compose build --no-cache
docker compose up -d
```

---

### ğŸ“‹ Checklist aprÃ¨s un problÃ¨me

1. `docker compose ps` â†’ tous les containers sont `Up` ?
2. `docker compose logs backend --tail=30` â†’ erreur visible ?
3. `docker compose exec ollama ollama list` â†’ modÃ¨les prÃ©sents ?
4. `docker compose exec backend python -c "from app.services.docling_service import _DOCLING_OK; print(_DOCLING_OK)"` â†’ Docling OK ?
5. Test API direct avec curl â†’ le backend rÃ©pond ?
6. Si tout est OK cÃ´tÃ© API â†’ rebuild frontend : `docker compose build --no-cache frontend && docker compose up -d frontend`
